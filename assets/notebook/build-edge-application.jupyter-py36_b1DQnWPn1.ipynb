{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# build-edge-application\n\nBuild the IBM Streams Application for the Micro-Edge.\nIncludes the pre-built HandwrittenDigits_Model into the micro-edge application bundle.\nAlso includes the MNIST test dataset to simulate a camera feeding in images to the application.\n\nAs each image is processed, it is first cleaned up, grayscaled, cropped, centered, and re-sized, to ensure each image is in the\nformat the model expects (note that the MNIST test dataset is already ready for scoring, but the pre-processing is still done as an example of\npre-model preparatory work micro-edge Streams applications can do).\n\nAfter pre-processing, each image is scored against the pre-build model included in the application bundle.  The model is loaded into memory when the job starts running at the edge.\nIf the `parallelism` parameter is specified when creating the Edge deployment package, several parallel instances of the model can be used, to increase image throughput through the application.\n\nWhile the sample application doesn't take action at the micro-edge based on the scored results, typically it would do so, perhaps 'rejecting' invalid products on a product line, or sorting items, etc.\n\nThe sample application does, however, check the level of confidence in the digit prediction, and if the confidence is too low (defaults to below 70%, can be controlled by setting the `confidence` parameter when creating the Edge deployment package), the image and the scores the model found for it are sent back to the CPD Hub, over an Event Streams topic.\n\nAdditionally, the sample application collects aggregate metrics on image throughput, latencies involved with pre-processing and scoring, and prediction distributions, and periodically sends those metrics back to the CPD Hub (over the same Event Streams topic) for display, monitoring, or further analysis.\n"}, {"metadata": {}, "cell_type": "code", "source": "!pip install --upgrade --user 'streamsx>=1.15.8'\n!pip install --upgrade scikit-learn==0.21.3\n!pip install streamsx.eventstreams\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import os\nimport sys\nimport json\nimport datetime\nimport getpass\nimport numpy as np\nimport time\nimport base64\nimport socket\n\n# Make sure this is first in the list...\nsys.path.insert(0, '/home/wsuser/.local/lib/python3.6/site-packages')\n\nfrom streamsx.topology.topology import Topology\nfrom streamsx.topology import context\nimport streamsx.ec\nimport streamsx.eventstreams as eventstreams\nprint(\"Streamsx version:\",streamsx.ec.__version__)\n\nif '/project_data/data_asset' not in sys.path:\n    sys.path.insert(0, '/project_data/data_asset')\n\nfrom image_source import ImageSource\nfrom image_classifier import DigitPredictor, compute_metrics, ImagePrep\n\n# Grab Streams instance config object and REST reference\nfrom icpd_core import icpd_util\nSTREAMS_INSTANCE_NAME = \"edge\"\nstreams_cfg=icpd_util.get_service_instance_details(name=STREAMS_INSTANCE_NAME)\n\nfrom streamsx.rest_primitives import Instance\nstreams_cfg[context.ConfigParams.SSL_VERIFY] = False\nstreams_instance = Instance.of_service(streams_cfg)\n\n# Model Name\nMODEL_NAME = 'HandwrittenDigits_Model'\n\n# How confident we have to be in the prediction to not send it home.\n# This is just the default. Can be changed at submission time.\nCONFIDENCE_THRESHOLD = 0.70\n\n# Metrics aggregation window duration (in seconds)\nMETRICS_DURATION = 10\n\n# Eventstreams topics\nEVENTSTREAMS_TOPIC = 'DefaultTopic'\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Enter in your Eventstreams credentials as JSON\neventstreams_credentials_json = getpass.getpass('Your Event Streams credentials:')\neventstreams_credentials = json.loads(eventstreams_credentials_json)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "class Enricher(object):\n    \"\"\"\n    Callable class that base64 encodes the image data, and adds some metadata to each tuple, including camera id/uid, timestamp, etc.\n    \n    \"\"\"\n\n    def __init__(self, get_camera_id):\n        # Note this method is only called when the topology is\n        # declared to create a instance to use in the map function.\n        self.get_camera_id = get_camera_id\n        self._uid = None\n        self._cam_name = None\n\n    def __call__(self, t):\n        t['image'] = base64.b64encode(t['image']).decode('utf-8')\n        t['camera'] = self._cam_name\n        t['timestamp'] = datetime.datetime.utcnow().isoformat() + 'Z'\n\n        return t\n\n    def __enter__(self):\n        # Called at runtime in the IBM Streams job before\n        # this instance starts processing tuples.\n        self._uid = socket.gethostname()\n        self._cam_name = self.get_camera_id() + \"-\" + self._uid\n        print(\"Camera name:\", self._cam_name, flush=True)\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        # __enter__ and __exit__ must both be defined.\n        pass\n        ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Build the application flow graph toplogy\ndef createEdgeCameraClassifierTopology():\n    topo = Topology(name=\"EdgeCameraClassifier\")\n\n    # Add some Python dependencies into the edge application bundle\n    topo.add_pip_package('scikit-learn==0.21.3')\n    topo.add_pip_package('numpy')\n    topo.add_pip_package('Pillow')\n    topo.add_pip_package('joblib')\n\n    # Ensure the model is pulled into the edge application bundle\n    model_path = topo.add_file_dependency(os.path.join('/project_data/data_asset',MODEL_NAME), 'etc')\n\n    \n    # Create submission parameters\n    # Threshold of certainty\n    get_confidence_threshold = topo.create_submission_parameter('confidence', default=CONFIDENCE_THRESHOLD)\n    \n    # Initial parallel widths\n    get_scoring_parallelism = topo.create_submission_parameter('parallelism', default=1)\n\n    # Create submission parameters\n    # How many times to repeat the dataset.  0 indicates to repeat forever.\n    get_repeat_count = topo.create_submission_parameter('repeat', default=0)\n    \n    # Delay between sending images, in seconds.  0 indicates to not delay at all.\n    get_delay = topo.create_submission_parameter('delay', default=0.0)\n    \n    # Camera id to use for this source\n    get_camera_id = topo.create_submission_parameter('camera', default='Camera')\n    \n    # Source type is unused here, but some operators expect it, to help chosing a different sample image source\n    get_source_type = lambda : 0 # source type of 0 is the MNIST test dataset we add below.\n \n    # Pull in the images and MNIST index files we use to get images to push through\n    dataset_dirs = []\n    dataset_dirs.append(topo.add_file_dependency('/project_data/data_asset/mnist-test-images', 'etc'))\n    \n        \n    # Start sending images\n    images = topo.source(ImageSource(get_source_type, \n                                     dataset_dirs,\n                                     delay=get_delay,\n                                     repeat=get_repeat_count),\n                         name=\"ImageSource\")\n    \n    # Enrich the images streams with camera id and timestamp\n    images_enriched = images.map(Enricher(get_camera_id),\n                                 name=\"EnrichImages\")\n    \n    # Enrich the incoming tuples, and pre-process the images into a form the model expects\n    prepared_images = images_enriched.map(ImagePrep(), name=\"PrepareImages\")\n    \n    # Now do actual classification of the image using the DigitPredictor class.\n    # Allow this to be parallelized\n    reparallel_prepared_images = prepared_images.parallel(get_scoring_parallelism)\n    parallel_image_predictions = reparallel_prepared_images.map(DigitPredictor(model_path), name='PredictDigit')\n    classified = parallel_image_predictions.end_parallel()\n    \n    # Dummy operator to make the graph easier to understand\n    dummy = classified.map(lambda t: t, name=\"RecombineClassified\")\n    \n    # Filter out the certain predictions, and keep the uncertain ones to send home.\n    # Also, for testing, send everything from Test cameras home as well.\n    uncertain_predictions = dummy.filter(lambda t: t['result_probability'] <= get_confidence_threshold() or t['camera'].startswith(\"Test\"),\n                                              name='CertaintyFilter')\n    \n    # Get a stream that is just the result class and camera id for aggregated metrics\n    simplified = dummy.map(lambda t: {'camera': t['camera'],\n                                           'result_class': t['result_class'],\n                                           'result_probability': t['result_probability'],\n                                           'prep_time': t['prep_time'],\n                                           'predict_time': t['predict_time'],\n                                           'timestamp': t['timestamp']},\n                                name='SimplifyClassifications')\n    \n    \n    # Send home predicted images that we're not sure about, through a kafka topic\n    sendhome_uncertain_images = uncertain_predictions.as_json()\n    eventstreams.publish(sendhome_uncertain_images, topic=EVENTSTREAMS_TOPIC, credentials=eventstreams_credentials, name=\"SendHomeUncertainImages\")\n    \n    # Do some other processing for each prediction (here, we do nothing)\n    result = simplified.map(lambda x : None, name='FurtherProcessing')\n \n    \n    # Aggregate classifications, over time windows\n    metrics_windows = simplified.batch(size=datetime.timedelta(seconds=METRICS_DURATION))\n    metrics = metrics_windows.aggregate(lambda v: compute_metrics(v, get_confidence_threshold(), METRICS_DURATION, get_delay(), get_repeat_count(), get_scoring_parallelism(), get_source_type()), name='ComputeDigitMetrics')\n    \n    # Periodically send classification metrics home, through a kafka topic\n    sendhome_metrics = metrics.as_json()\n    sendhome_metrics.view(name=\"metrics_view\")\n    eventstreams.publish(sendhome_metrics, topic=EVENTSTREAMS_TOPIC, credentials=eventstreams_credentials, name=\"SendHomeClassificationMetrics\")\n    \n    \n    return topo\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Build the topology into a bundle file for later submission\ntopo =  createEdgeCameraClassifierTopology()\n\n# Set the job config\njob_config = context.JobConfig(job_name = topo.name, tracing = \"debug\")\njob_config.raw_overlay = {'edgeConfig': {'imageName':'edge-camera-classifier-app', 'imageTag': 'v1', 'pipPackages': ['scikit-learn==0.21.3'], 'rpms': []}}\njob_config.add(streams_cfg)\n\n# Actually build the job, and push to edge image repo.\nprint(\"Building new job:\", topo.name)\n\nsubmission_result = context.submit('EDGE', topo, streams_cfg)\nif submission_result.return_code == 0:\n    print(\"Job Bundle built successfully.\")\n    print(\"  Image:       %s\" % (submission_result['image'],))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}