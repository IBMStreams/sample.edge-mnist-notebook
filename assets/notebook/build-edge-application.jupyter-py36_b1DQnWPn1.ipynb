{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Build the IBM Streams Application for the Edge\n\nPulls the pre-built HandwrittenDigits_Model into the edge application bundle.\nInput images are read in from an IBM Streams local topic (named 'camera_images'), with tuples containing:\n- image - the binary PNG blob of the image\n- camera - a camera id\n- timestamp - the timestamp of the image being captured\n\nThe Image is prepped for scoring, then scored using the pre-built model loaded at application startup.\nThe prediction is recorded, and certainty of prediction is used to determine if we need to send the raw image back home for training improvements.\nPeriodically, prediction metrics are also sent home for higher level analysis.\n"}, {"metadata": {}, "cell_type": "code", "source": "!pip install --upgrade --user 'streamsx>=1.15.8'\n!pip install --upgrade scikit-learn==0.21.3\n!pip install streamsx.eventstreams\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import os\nimport sys\nimport json\nimport datetime\nimport getpass\nimport numpy as np\nimport time\nimport base64\nimport socket\n\n# Make sure this is first in the list...\nsys.path.insert(0, '/home/wsuser/.local/lib/python3.6/site-packages')\n\nfrom streamsx.topology.topology import Topology\nfrom streamsx.topology import context\nimport streamsx.ec\nimport streamsx.eventstreams as eventstreams\nprint(\"Streamsx version:\",streamsx.ec.__version__)\n\nif '/project_data/data_asset' not in sys.path:\n    sys.path.insert(0, '/project_data/data_asset')\n\nfrom image_source import ImageSource\nfrom image_classifier import DigitPredictor, compute_metrics, ImagePrep\n\n# Grab Streams instance config object and REST reference\nfrom icpd_core import icpd_util\nSTREAMS_INSTANCE_NAME = \"edge\"\nstreams_cfg=icpd_util.get_service_instance_details(name=STREAMS_INSTANCE_NAME)\n\nfrom streamsx.rest_primitives import Instance\nstreams_cfg[context.ConfigParams.SSL_VERIFY] = False\nstreams_instance = Instance.of_service(streams_cfg)\n\n# Model Name\nMODEL_NAME = 'HandwrittenDigits_Model'\n\n# How confident we have to be in the prediction to not send it home.\n# This is just the default. Can be changed at submission time.\nCONFIDENCE_THRESHOLD = 0.70\n\n# Metrics aggregation window duration (in seconds)\nMETRICS_DURATION = 10\n\n# Eventstreams topics\nUNCERTAIN_PREDICTIONS_EVENTSTREAMS_TOPIC = 'DefaultTopic'\nMETRICS_EVENTSTREAMS_TOPIC = 'DefaultTopic'\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Enter in your Eventstreams credentials as JSON\neventstreams_credentials_json = getpass.getpass('Your Event Streams credentials:')\neventstreams_credentials = json.loads(eventstreams_credentials_json)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "class Enricher(object):\n    \"\"\"\n    Callable class that base64 encodes the image data, and adds some metadata to each tuple, including camera id/uid, timestamp, etc.\n    \n    \"\"\"\n\n    def __init__(self, get_camera_id):\n        # Note this method is only called when the topology is\n        # declared to create a instance to use in the map function.\n        self.get_camera_id = get_camera_id\n        self._uid = None\n        self._cam_name = None\n\n    def __call__(self, t):\n        t['image'] = base64.b64encode(t['image']).decode('utf-8')\n        t['camera'] = self._cam_name\n        t['timestamp'] = datetime.datetime.utcnow().isoformat() + 'Z'\n\n        return t\n\n    def __enter__(self):\n        # Called at runtime in the IBM Streams job before\n        # this instance starts processing tuples.\n        self._uid = socket.gethostname()\n        self._cam_name = self.get_camera_id() + \"-\" + self._uid\n        print(\"Camera name:\", self._cam_name, flush=True)\n\n    def __exit__(self, exc_type, exc_value, traceback):\n        # __enter__ and __exit__ must both be defined.\n        pass\n        ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Build the application flow graph toplogy\ndef createEdgeCameraClassifierTopology():\n    topo = Topology(name=\"EdgeCameraClassifier\")\n\n    # Add some Python dependencies into the edge application bundle\n    topo.add_pip_package('scikit-learn==0.21.3')\n    topo.add_pip_package('numpy')\n    topo.add_pip_package('Pillow')\n    topo.add_pip_package('joblib')\n\n    # Ensure the model is pulled into the edge application bundle\n    model_path = topo.add_file_dependency(os.path.join('/project_data/data_asset',MODEL_NAME), 'etc')\n\n    \n    # Create submission parameters\n    # Threshold of certainty\n    get_confidence_threshold = topo.create_submission_parameter('confidence', default=CONFIDENCE_THRESHOLD)\n    \n    # Initial parallel widths\n    get_scoring_parallelism = topo.create_submission_parameter('parallelism', default=1)\n\n    # Create submission parameters\n    # How many times to repeat the dataset.  0 indicates to repeat forever.\n    get_repeat_count = topo.create_submission_parameter('repeat', default=0)\n    \n    # Delay between sending images, in seconds.  0 indicates to not delay at all.\n    get_delay = topo.create_submission_parameter('delay', default=0.0)\n    \n    # Camera id to use for this source\n    get_camera_id = topo.create_submission_parameter('camera', default='Camera')\n    \n    # Source type is unused here, but some operators expect it, to help chosing a different sample image source\n    get_source_type = lambda : 0 # source type of 0 is the MNIST test dataset we add below.\n \n    # Pull in the images and MNIST index files we use to get images to push through\n    dataset_dirs = []\n    dataset_dirs.append(topo.add_file_dependency('/project_data/data_asset/mnist-test-images', 'etc'))\n    \n        \n    # Start sending images\n    images = topo.source(ImageSource(get_source_type, \n                                     dataset_dirs,\n                                     delay=get_delay,\n                                     repeat=get_repeat_count),\n                         name=\"ImageSource\")\n    \n    # Enrich the images streams with camera id and timestamp\n    images_enriched = images.map(Enricher(get_camera_id),\n                                 name=\"EnrichImages\")\n    \n    # Enrich the incoming tuples, and pre-process the images into a form the model expects\n    prepared_images = images_enriched.map(ImagePrep(), name=\"PrepareImages\")\n    \n    # Now do actual classification of the image using the DigitPredictor class.\n    # Allow this to be parallelized\n    reparallel_prepared_images = prepared_images.parallel(get_scoring_parallelism)\n    parallel_image_predictions = reparallel_prepared_images.map(DigitPredictor(model_path), name='PredictDigit')\n    classified = parallel_image_predictions.end_parallel()\n    \n    # Dummy operator to make the graph easier to understand\n    dummy = classified.map(lambda t: t, name=\"RecombineClassified\")\n    \n    # Filter out the certain predictions, and keep the uncertain ones to send home.\n    # Also, for testing, send everything from Test cameras home as well.\n    uncertain_predictions = dummy.filter(lambda t: t['result_probability'] <= get_confidence_threshold() or t['camera'].startswith(\"Test\"),\n                                              name='CertaintyFilter')\n    \n    # Get a stream that is just the result class and camera id for aggregated metrics\n    simplified = dummy.map(lambda t: {'camera': t['camera'],\n                                           'result_class': t['result_class'],\n                                           'result_probability': t['result_probability'],\n                                           'prep_time': t['prep_time'],\n                                           'predict_time': t['predict_time'],\n                                           'timestamp': t['timestamp']},\n                                name='SimplifyClassifications')\n    \n    \n    # Send home predicted images that we're not sure about, through a kafka topic\n    sendhome_uncertain_images = uncertain_predictions.as_json()\n    eventstreams.publish(sendhome_uncertain_images, topic=UNCERTAIN_PREDICTIONS_EVENTSTREAMS_TOPIC, credentials=eventstreams_credentials, name=\"SendHomeUncertainImages\")\n    \n    # Do some other processing for each prediction (here, we do nothing)\n    result = simplified.map(lambda x : None, name='FurtherProcessing')\n \n    \n    # Aggregate classifications, over time windows\n    metrics_windows = simplified.batch(size=datetime.timedelta(seconds=METRICS_DURATION))\n    metrics = metrics_windows.aggregate(lambda v: compute_metrics(v, get_confidence_threshold(), METRICS_DURATION, get_delay(), get_repeat_count(), get_scoring_parallelism(), get_source_type()), name='ComputeDigitMetrics')\n    \n    # Periodically send classification metrics home, through a kafka topic\n    sendhome_metrics = metrics.as_json()\n    sendhome_metrics.view(name=\"metrics_view\")\n    eventstreams.publish(sendhome_metrics, topic=METRICS_EVENTSTREAMS_TOPIC, credentials=eventstreams_credentials, name=\"SendHomeClassificationMetrics\")\n    \n    \n    return topo\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Build the topology into a bundle file for later submission\ntopo =  createEdgeCameraClassifierTopology()\n\n# Set the job config\njob_config = context.JobConfig(job_name = topo.name, tracing = \"debug\")\njob_config.raw_overlay = {'edgeConfig': {'imageName':'edge-camera-classifier-app', 'imageTag': 'v1', 'pipPackages': ['scikit-learn==0.21.3'], 'rpms': []}}\njob_config.add(streams_cfg)\n\n# Actually build the job, and push to edge image repo.\nprint(\"Building new job:\", topo.name)\n\nsubmission_result = context.submit('EDGE', topo, streams_cfg)\nif submission_result.return_code == 0:\n    print(\"Job Bundle built successfully.\")\n    print(\"  Image:       %s\" % (submission_result['image'],))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}