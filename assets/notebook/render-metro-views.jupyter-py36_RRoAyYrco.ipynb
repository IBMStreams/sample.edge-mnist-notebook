{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# render-metro-views\n\nDisplay the views that the metro-edge application is providing. \n\n#### Before you begin,  verify that you've executed [build-metro-application](./build-metro-application.jupyter-py36.ipynb) notebook.\nThe build-metro-application notebook composes and submits the metro application that recieves status from the edge, this notebook renders data from the metro application.\n\nThe metro application receives two types of messages on a topic from the edge. The 'ClassificationMetrics' messages provide statistics on the scoring on the edge, these messages are aggregated for time averaging. The 'UncertainImages' messages contains images that have a lower-than-acceptable confidence rating that require deeper analysis and possible manual labelling.\n\nThis notebook renders the data processed by the metro application. "}, {"metadata": {}, "cell_type": "code", "source": "%matplotlib inline\n%gui asyncio\nimport urllib3\nimport time\nimport threading\nimport base64\nimport sys\nimport IPython\n#from IPython import display  ## DO NOT use interferes with display()\nimport ipywidgets as widgets\nfrom ipywidgets.widgets.interaction import show_inline_matplotlib_plots\nfrom IPython.core.debugger import set_trace\n## \nfrom icpd_core import icpd_util\nfrom streamsx.rest_primitives import Instance\nfrom streamsx.topology import context\n\nif '/project_data/data_asset' not in sys.path:\n    sys.path.insert(0, '/project_data/data_asset')\nimport metrorender\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Cell to grab Streams instance config object and REST reference\nurllib3.disable_warnings()\nSTREAMS_INSTANCE_NAME = \"edge\"\nstreams_cfg=icpd_util.get_service_instance_details(name=STREAMS_INSTANCE_NAME)\nstreams_cfg[context.ConfigParams.SSL_VERIFY] = False\ninstance = Instance.of_service(streams_cfg)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Verify that the Metro-Edge Streams Application is active and healthy"}, {"metadata": {}, "cell_type": "code", "source": "# Verify that the job is healthy/up before proceding..\n#\nurllib3.disable_warnings()\n# list the active jobs\nprint(\"Active Jobs:\")\nfor job in instance.get_jobs():\n    print(\"  \", job.name, job.health)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Bring up the live Queues of Views\n- ClassificationMetrics\n- WindowUncertain"}, {"metadata": {}, "cell_type": "code", "source": "# WindowUncertain - queue\noutput_WindowUncertain = widgets.Output()\ndisplay(output_WindowUncertain )\nWindowUncertain_vtq = metrorender.view_to_queue(instance, \"WindowUncertain\", output_WindowUncertain)\nWindowUncertain_vtq.start()  # start\n#print(\"windowUncertain_thread\\n\\t alive:{}\\n\\t event:{}\\n\\t queue depth:{}\".format(WindowUncertain_vtq.thread.is_alive(), WindowUncertain_vtq.event.is_set(), len(WindowUncertain_vtq.tuples)))\n# WindowUncertain_vtq.event.clear()  # emergency kill\n\n# UncertainPredictions - queue\noutput_UncertainPredictions = widgets.Output()\ndisplay(output_UncertainPredictions )\nUncertainPredictions_vtq = metrorender.view_to_queue(instance, \"UncertainPredictions\", output_UncertainPredictions)\nUncertainPredictions_vtq.start()  # start\n#print(\"UncertainPredictions_thread\\n\\t alive:{}\\n\\t event:{}\\n\\t queue depth:{}\".format(UncertainPredictions_vtq.thread.is_alive(), UncertainPredictions_vtq.event.is_set(), len(UncertainPredictions_vtq.tuples)))\n# UncertainPredictions_vtq.event.clear()  # emergency kill", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Specify the cameras\n\nDiscover the cameras that are available by waiting for events for 10 seconds, during which time at least one ClassificationMetrics message should have arrived, with the list of\ncurrently active cameras, which is displayed.  If you wish to override the discovered set of cameras, to only show metrics from a subset, set the ACTIVE_CAMERAS to that subset.\n"}, {"metadata": {}, "cell_type": "code", "source": "import json\n# Wait a bit for the camera metrics to come in.\ntime.sleep(10)\nchunks = WindowUncertain_vtq.tuples.copy()\nACTIVE_CAMERAS = set({})\nfor chunk in chunks:\n    for tups in chunk:\n        #tup = json.loads(tups)\n        tup = tups\n        key_list = tup['camera_metrics'].keys()\n        ACTIVE_CAMERAS.add(list(key_list)[0])\n\n# Uncomment to override the detected cameras\n#ACTIVE_CAMERAS = {'Camera-X', 'Camera-Y'}\n\nACTIVE_CAMERAS", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Per-Camera Digit Prediction Metrics\n\nFor each camera, the current image throughput is shown, along with a graph showing the distribution of all images in the recent interval that were predicted to be each digit.  The two bars for each digit show the certain vs. uncertain predictions for each digit.\n\nThe graphs will continue to update based on the most recent metrics until you Interrupt the kernel, to move on to the next cell."}, {"metadata": {}, "cell_type": "code", "source": "#%%script false --no-raise-error\nidx = 1\nwhile (len(WindowUncertain_vtq.tuples) < 5):\n    print(\"priming{}\".format(idx*\".\"),end=\"\\n\")\n    idx += 1\n    time.sleep(2)\nprint(\"primed           \")\noutput_graphs = widgets.Output()\ndisplay(output_graphs)\nsynchronous_event = threading.Event()\nsynchronous = metrorender.deque_synchronous(WindowUncertain_vtq.tuples, count=5, debug=False)\nrwu =  metrorender.RenderWindowUncertain(output_graphs, ACTIVE_CAMERAS)\ntry: \n    rwu.render(synchronous,synchronous_event)\nexcept KeyboardInterrupt:\n    print(\"Interrupt caught...\")\n    rwu.class_status_widget.value = \"Interupt * Finished\"\nrwu.class_status_widget.value = \"Rendering - Finished\"\n ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Display sampled set uncertain images\n\nAs images are scored, images where the model's prediction confidence for any given digit is too low are returned\nto the Metro-edge. There, these images could be manually scored, and potentially used to build a more robust model.\n\nBelow is a sampling of the uncertain images that were returned to the metro-edge recently.  They will continue updating\nuntil the kernel is Interrupted, to move on to the next cell.\n"}, {"metadata": {}, "cell_type": "code", "source": "#%%script false --no-raise-error\n# Un-threaded version\noutput_uncertain = widgets.Output()\ndisplay(output_uncertain)\nrui = metrorender.RenderUncertainImages(output_uncertain)\nrui.stop_button.description = \"Use Interrupt\"\nrui.stop_button.tooltip = \"Use Interrupt Kernel above\"\nactive = True\ntry:\n    while active:\n        try:\n            rui.display_view(UncertainPredictions_vtq.tuples.pop(), \"live\")\n            time.sleep(.7) # slow down - prevent widget overrun\n        except IndexError:\n            time.sleep(3)\nexcept KeyboardInterrupt:\n    active = False\n    rui.interrupt_stopped(\"Review displayed Images\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Correction Station\n\nThe current model is not perfect.  When it encounters images that it cannot classify with confidence, these images are sent down the 'UncertainPrediction' view. In order to improve the model, the questionable images need to be assigned a value and added into the training data for the next round of model regeneration. The purpose of this\ndashboard is to review the questionable images and either accept the predicted label, or adjust the label as necessary.\n\nIn an environment where the images are the output of a camera on the edge, say in a manufacturing line, not all incorrect predictions are the result of a poor model: in some cases the camera may be faulting, or misaligned, or the lighting may have been lost, etc.  For some of these cases, the model may still be improved to be more robust in these error situations, but in other cases, the root problem should be fixed, but the incorrect images shouldn't be used to re-train the model, and so should be discarded.\n\nIn a full solution, mocked up here, the questionable images are displayed to the left, and their per-digit scores (according to the current model) are displayed to the right, with a default predicted label chosen.  The user could adjust the label if they are confident in the correct one, or ask for a second opinion, or declare that there is a camera issue, or some other problem.  As each image is handled, the next arrow at the bottom can be used to move on to the next image to manually label.  When a particular manual labeling session is complete, the \"Training Upload\" button might be used to send the manually labeled images to some database that will be used when the model is next re-built.\n"}, {"metadata": {}, "cell_type": "code", "source": "#%%script false --no-raise-error\n\nwhile len(UncertainPredictions_vtq.tuples)< 20:\n    time.sleep(3)\n    print(\" - waiting for events ...\")\nsnapShot = UncertainPredictions_vtq.tuples.copy()\ncd = metrorender.CorrectionDashboard()\ncd.render_review(snapShot)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "pycharm": {"stem_cell": {"cell_type": "raw", "metadata": {"collapsed": false}, "source": []}}}, "nbformat": 4, "nbformat_minor": 4}