{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# build-metro-application\n\nBuilds metro appliction that accepts Kafka messages from the edge(s). \n\nAggregates/Analyze messages \n- push to storage\n- generate events \n- send notifcations\n- deep analysis\n- host views to monitor the 'goings on'."}, {"metadata": {}, "cell_type": "code", "source": "!pip install streamsx.eventstreams", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import urllib3\nimport time\nimport json\nimport os\nimport sys\nimport collections\nimport warnings\n\nfrom streamsx.topology.topology import Topology\nfrom streamsx.topology.schema import CommonSchema\nfrom streamsx.topology.context import submit, ContextTypes\nimport streamsx.eventstreams as eventstreams\n\nfrom streamsx.rest_primitives import Instance\nfrom streamsx.topology import context\nimport streamsx.rest as rest\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "urllib3.disable_warnings()\n# Cell to grab Streams instance config object and REST reference\nfrom icpd_core import icpd_util\nSTREAMS_INSTANCE_NAME = \"edge\"\nstreams_cfg=icpd_util.get_service_instance_details(name=STREAMS_INSTANCE_NAME)\nstreams_cfg[context.ConfigParams.SSL_VERIFY] = False\nstreams_instance = Instance.of_service(streams_cfg)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "## Define the EventStreams topics to access \nEVENTSTREAMS_TOPIC = 'DefaultTopic'\n\n# The eventstreams group id to use as a base\nGROUP_NAME_BASE = 'MetroEdge-'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Enter in your Eventstreams credentials as JSON\nimport getpass\neventstreams_credentials_json = getpass.getpass('Your Event Streams credentials:')\napp_config_name = eventstreams.configure_connection(streams_instance, name='eventstreams', credentials=eventstreams_credentials_json)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "class SlideWindow(object):\n    \"\"\" Window with slide_length elements. \n    \n    Window fills, intial output will have less than slide_length.\n    \n    Args:\n        slide_length: maximum number of elements in window.\n        \n    Returns:\n        list of up to 25 of the last tups input.\n    \"\"\"\n    def __init__(self, slide_length:int=25):\n        self.slide_length = slide_length\n\n    def __enter__(self):\n        self.chunk = collections.deque(maxlen=self.slide_length)\n        \n    def __exit__(self, exc_type, exc_value, traceback):\n        # __enter__ and __exit__ must both be defined.\n        pass\n    \n    def __call__(self, tup) -> list:\n        self.chunk.append(tup)\n        return list(self.chunk)\n        ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "urllib3.disable_warnings()\ndef build_metro() -> Topology:\n    \"\"\" metro application subscribing to two topics \n    \n    * Subscribed topics are reflected out view.\n    * Metrics are windowed\n    \n    Returns:\n        Topology of the application. \n    \"\"\"\n    topo = Topology('EdgeMetroSubscribe')\n    # Subscribe to same topic as a stream \n\n    # All items in the feed\n    combined_feed = eventstreams.subscribe(topo, schema=CommonSchema.Json, topic=EVENTSTREAMS_TOPIC, group=GROUP_NAME_BASE + EVENTSTREAMS_TOPIC, credentials=app_config_name)\n    from_evstr1 = combined_feed.filter(lambda t: \"camera_metrics\" in t)\n\n    # collect Collect Metrics\n    from_evstr1.view(name=\"ClassificationMetrics\")\n    from_evstr1.print(name=\"classificationPrint\")\n\n    # window the Metrics\n    windowSlide = from_evstr1.map(SlideWindow())\n    windowSlide.view(name=\"WindowUncertain\")\n    windowSlide.print(name=\"windowPrint\")\n\n    # Collect the uncertain predictions\n    from_evstr2 = combined_feed.filter(lambda t: \"image\" in t)\n    from_evstr2.view(name=\"UncertainPredictions\")\n    from_evstr2.print(name=\"uncertainPrint\")\n\n    return topo\n\n# Generate the topology\ntopo = build_metro()\n\n# Cancel the job from the instance if it is already running...\nfor job in streams_instance.get_jobs():\n    if job.name == topo.name:\n        print(\"Cancelling old job:\", job.name)\n        job.cancel()\n    \n# Setup the job config\njob_config = context.JobConfig(job_name = topo.name, tracing = \"debug\")\njob_config.add(streams_cfg)\n    \n# Actually submit the job\nprint(\"Building and submitting new job:\", topo.name)\nsubmission_result = context.submit('DISTRIBUTED', topo, streams_cfg)\n\nif submission_result.return_code == 0:\n    print(\"Job built and submitted successfully.\")\n    print(\"  Job ID:\",submission_result.jobId)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Monitor from metro. \n\nOnce the metro is up and running the [render-metro-views.jupyter-py36.ipynb](render-metro-views.jupyter-py36.ipynb) notebook can monitor and enhance the processing."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.10", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 4}